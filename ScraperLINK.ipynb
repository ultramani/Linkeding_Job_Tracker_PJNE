{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9de85ef8-e5aa-44ea-b4dc-0893563d441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl.worksheet.datavalidation import DataValidation\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.formatting.rule import FormulaRule\n",
    "from openpyxl.styles import Font, Alignment, Border, Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719810d3-8a99-407b-93bd-2137d9354264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_with_backoff(url, max_retries=6, timeout=20):\n",
    "    \"\"\"\n",
    "    Retries on 429 (rate limit) with exponential backoff + jitter.\n",
    "    Respects Retry-After header when present.\n",
    "    Also retries on 5xx and some network errors.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            r = session.get(url, timeout=timeout)\n",
    "\n",
    "            # Debug (optional)\n",
    "            print(r.status_code, r.headers.get(\"Retry-After\"))\n",
    "\n",
    "            # Handle rate limiting\n",
    "            if r.status_code == 429:\n",
    "                retry_after = r.headers.get(\"Retry-After\")\n",
    "                if retry_after:\n",
    "                    # Retry-After can be seconds. If it's a date, this may fail -> fallback.\n",
    "                    try:\n",
    "                        wait = float(retry_after)\n",
    "                    except ValueError:\n",
    "                        wait = (2 ** attempt) + random.uniform(0.5, 1.5)\n",
    "                else:\n",
    "                    wait = (2 ** attempt) + random.uniform(0.5, 1.5)\n",
    "\n",
    "                print(f\"429 rate-limited. Sleeping {wait:.2f}s then retrying... ({attempt+1}/{max_retries})\")\n",
    "                time.sleep(wait)\n",
    "                continue\n",
    "\n",
    "            # Retry transient server errors\n",
    "            if 500 <= r.status_code < 600:\n",
    "                wait = (2 ** attempt) + random.uniform(0.5, 1.5)\n",
    "                print(f\"{r.status_code} server error. Sleeping {wait:.2f}s then retrying... ({attempt+1}/{max_retries})\")\n",
    "                time.sleep(wait)\n",
    "                continue\n",
    "\n",
    "            # Raise for other non-200s (403, 404, etc.)\n",
    "            r.raise_for_status()\n",
    "            return r\n",
    "\n",
    "        except (requests.exceptions.Timeout,\n",
    "                requests.exceptions.ConnectionError,\n",
    "                requests.exceptions.ChunkedEncodingError) as e:\n",
    "            wait = (2 ** attempt) + random.uniform(0.5, 1.5)\n",
    "            print(f\"Network error: {e}. Sleeping {wait:.2f}s then retrying... ({attempt+1}/{max_retries})\")\n",
    "            time.sleep(wait)\n",
    "\n",
    "    raise RuntimeError(f\"Failed after {max_retries} retries: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cbe30ce9-2fac-4acb-8e09-f5cd316dfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data that the user will be able to change\n",
    "jobTitle = \"Junior Python\"\n",
    "location = \"Spain\"\n",
    "# Limit it to 1 type\n",
    "workType = \"en remoto\"\n",
    "# WiLL default to 10\n",
    "numberOfJobs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ae559703-babf-4431-9e21-c3cacc8749c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Junior%20Python&location=Spain&f_WT=2\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Junior%20Python&location=Spain&f_WT=2&start=10\n",
      "{'4375730080', '4344868693', '4371175870', '4344099336', '4344753207', '4345824234', '4368612475', '4343901472', '4373999796', '4376580751', '4377139056', '4344139135', '4342452527', '4272412678', '4344988192', '4370527191', '4348296606', '4344898728', '4344958263', '4225591133'}\n"
     ]
    }
   ],
   "source": [
    "job_id_list = set()\n",
    "jobTitleFormatted = jobTitle.replace(' ', \"%20\")\n",
    "\n",
    "pageNumber = 0\n",
    "pageNumberObj =  math.ceil(numberOfJobs / 10)\n",
    "numberResults = \"\"\n",
    "\n",
    "wt_map = {\n",
    "    \"en remoto\": \"2\",\n",
    "    \"hibrido\": \"3\",\n",
    "    \"presencial\": \"1\"\n",
    "}\n",
    "wt_value = wt_map.get(workType)\n",
    "WT = f\"f_WT={wt_value}\"\n",
    "\n",
    "while pageNumber < pageNumberObj:\n",
    "    # Form the link\n",
    "    jobs_list_link = f\"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords={jobTitleFormatted}&location={location}&{WT}{numberResults}\"\n",
    "    print(jobs_list_link)\n",
    "    # Save the response in text and format it to get all job posts\n",
    "    response_jlg = requests.get(jobs_list_link)\n",
    "    jobs_list_data = response_jlg.text\n",
    "    jobs_list_soup = BeautifulSoup(jobs_list_data, \"html.parser\")\n",
    "    jobs_page = jobs_list_soup.find_all(\"li\")\n",
    "\n",
    "    # Get all job ids from the posts\n",
    "    for job in jobs_page:\n",
    "        base_card_div = job.find(\"div\", {\"class\": \"base-card\"})\n",
    "        job_id = base_card_div.get(\"data-entity-urn\").split(\":\")[3]\n",
    "        job_id_list.add(job_id)\n",
    "\n",
    "    pageNumber += 1\n",
    "    numberResults = f\"&start={pageNumber * 10}\" \n",
    "# Debug\n",
    "print(job_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "068e5f38-ccb3-4989-8641-3e3905d6452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "200 None\n",
      "Scraping ended\n"
     ]
    }
   ],
   "source": [
    "jobs_list = []\n",
    "session = requests.Session()\n",
    "\n",
    "for job_id in job_id_list:\n",
    "    job_especifics_link = f\"https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{job_id}\"\n",
    "\n",
    "    try:\n",
    "        response_je = get_with_backoff(job_especifics_link, max_retries=6)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping job_id {job_id} due to request failure: {e}\")\n",
    "        continue\n",
    "\n",
    "    job_soup = BeautifulSoup(response_je.text, \"html.parser\")\n",
    "    job_info = {\"job_id\": job_id}\n",
    "\n",
    "    # Job Title (raise if missing)\n",
    "    tag = job_soup.select_one(\"a.topcard__link h2.top-card-layout__title\")\n",
    "    if not tag:\n",
    "        print(f\"Missing job title for job_id {job_id} — skipping\")\n",
    "        continue\n",
    "    job_info[\"job_title\"] = tag.get_text(strip=True)\n",
    "    \n",
    "    # Company Info (raise if missing)\n",
    "    tag = job_soup.find(\"a\", class_=\"topcard__org-name-link\")\n",
    "    if not tag:\n",
    "        print(f\"Missing company tag for job_id {job_id} — skipping\")\n",
    "        continue\n",
    "    job_info[\"company_name\"] = tag.get_text(strip=True)\n",
    "    job_info[\"company_link\"] = f'=HYPERLINK(\"{tag.get(\"href\")}\",\"Link\")' \n",
    "    \n",
    "    # Workplace access (optional)\n",
    "    job_info[\"workplace_access\"] = workType\n",
    "\n",
    "    # Apply link \n",
    "    tag = job_soup.select_one(\"div.top-card-layout__entity-info a.topcard__link\")\n",
    "    job_info[\"apply_link\"] = f'=HYPERLINK(\"{tag.get(\"href\")}\",\"Link\")'  \n",
    "\n",
    "    # Job Type (optional)\n",
    "    tag = job_soup.select_one(\"span.posted-time-ago__text\")\n",
    "    job_info[\"work_type\"] = tag.get_text(strip=True) if tag else None\n",
    "\n",
    "    # Job Level and wory schedule (optional)\n",
    "    criteria_items = job_soup.select(\"li.description__job-criteria-item\")\n",
    "    \n",
    "    job_info[\"seniority_level\"] = None\n",
    "    job_info[\"employment_type\"] = None\n",
    "    \n",
    "    for item in criteria_items:\n",
    "        header = item.select_one(\"h3.description__job-criteria-subheader\")\n",
    "        value = item.select_one(\"span.description__job-criteria-text\")\n",
    "    \n",
    "        if not header or not value:\n",
    "            continue\n",
    "    \n",
    "        header_text = header.get_text(strip=True)\n",
    "    \n",
    "        if header_text == \"Seniority level\":\n",
    "            job_info[\"seniority_level\"] = value.get_text(strip=True)\n",
    "    \n",
    "        elif header_text == \"Employment type\":\n",
    "            job_info[\"employment_type\"] = value.get_text(strip=True)\n",
    "        \n",
    "    # Number of applicants (optional)\n",
    "    tag = job_soup.select_one(\"figcaption.num-applicants__caption\")\n",
    "    job_info[\"num_applicants\"] = tag.get_text(strip=True) if tag else None\n",
    "\n",
    "    # Time posted (optional)\n",
    "    tag = job_soup.select_one(\"span.posted-time-ago__text\")\n",
    "    job_info[\"time_posted\"] = tag.get_text(strip=True) if tag else None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    jobs_list.append(job_info)\n",
    "\n",
    "    # Gentle pacing between job detail requests (helps reduce 429s)\n",
    "    time.sleep(random.uniform(1.0, 2.5))\n",
    "\n",
    "print(\"Scraping ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a3648ea7-25f8-4050-8c48-bbfdf21a7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df = pd.DataFrame(jobs_list)\n",
    "#jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2651f7c1-5e99-44ef-81a9-ce74421a01ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_jobhunt_excel(FILE):\n",
    "    \"\"\"Run ONCE when the Excel is first created: Estado + dropdown + colors + header style.\"\"\"\n",
    "    wb = load_workbook(FILE)\n",
    "    ws = wb.active\n",
    "\n",
    "    STATUS_HEADER = \"Estado\"\n",
    "    options = [\"A aplicar\", \"Aplicado\", \"En revisión\", \"Aceptado\", \"Rechazado\"]\n",
    "    default_value = \"A aplicar\"\n",
    "\n",
    "    fills = {\n",
    "        \"A aplicar\": PatternFill(start_color='FFFFF2CC', end_color='FFFFF2CC', fill_type='solid'),  # amarillo\n",
    "        \"Aplicado\": PatternFill(start_color='FFD9E1F2', end_color='FFD9E1F2', fill_type='solid'),   # azul\n",
    "        \"En revisión\": PatternFill(start_color='FFE2EFDA', end_color='FFE2EFDA', fill_type='solid'),# verde claro\n",
    "        \"Aceptado\": PatternFill(start_color='FFC6EFCE', end_color='FFC6EFCE', fill_type='solid'),   # verde fuerte\n",
    "        \"Rechazado\": PatternFill(start_color='FFFFC7CE', end_color='FFFFC7CE', fill_type='solid'),  # rojo\n",
    "    }\n",
    "\n",
    "    headers = [ws.cell(row=1, column=c).value for c in range(1, ws.max_column + 1)]\n",
    "\n",
    "    # Create Estado only if missing (so it won't mess with your existing file)\n",
    "    if STATUS_HEADER not in headers:\n",
    "        ws.insert_cols(2)\n",
    "        status_col = 2\n",
    "        ws.cell(row=1, column=status_col, value=STATUS_HEADER)\n",
    "\n",
    "        # default values\n",
    "        for r in range(2, ws.max_row + 1):\n",
    "            ws.cell(row=r, column=status_col, value=default_value)\n",
    "\n",
    "        col_letter = ws.cell(row=1, column=status_col).column_letter\n",
    "        rng = f\"{col_letter}2:{col_letter}10000\"  # covers future rows too\n",
    "\n",
    "        # dropdown\n",
    "        dv = DataValidation(type=\"list\", formula1=f'\"{\",\".join(options)}\"', allow_blank=False)\n",
    "        ws.add_data_validation(dv)\n",
    "        dv.add(rng)\n",
    "\n",
    "        # conditional colors\n",
    "        for value, fill in fills.items():\n",
    "            rule = FormulaRule(formula=[f'${col_letter}2=\"{value}\"'], fill=fill)\n",
    "            ws.conditional_formatting.add(rng, rule)\n",
    "\n",
    "    # Header style (safe to re-run, but we call it once)\n",
    "    bold_font = Font(bold=True)\n",
    "    center_align = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "\n",
    "    black_side = Side(style=\"thin\", color=\"FF000000\")\n",
    "    border = Border(left=black_side, right=black_side, top=black_side, bottom=black_side)\n",
    "\n",
    "    for col in range(1, ws.max_column + 1):\n",
    "        cell = ws.cell(row=1, column=col)\n",
    "        cell.font = bold_font\n",
    "        cell.alignment = center_align\n",
    "        cell.border = border\n",
    "\n",
    "    ws.freeze_panes = \"A2\"\n",
    "    wb.save(FILE)\n",
    "\n",
    "\n",
    "def auto_resize_columns(FILE, min_w=10, max_w=85, padding=2):\n",
    "    \"\"\"Run EVERY time after writing the Excel: auto-fit column widths.\"\"\"\n",
    "    wb = load_workbook(FILE)\n",
    "    ws = wb.active\n",
    "\n",
    "    for col_cells in ws.columns:\n",
    "        col_letter = col_cells[0].column_letter\n",
    "        max_len = 0\n",
    "\n",
    "        for cell in col_cells:\n",
    "            value = cell.value\n",
    "            if value is None:\n",
    "                continue\n",
    "\n",
    "            # If you use =HYPERLINK(\"url\",\"Link\"), display is \"Link\"\n",
    "            if isinstance(value, str) and value.startswith(\"=HYPERLINK\"):\n",
    "                display = \"Link\"\n",
    "            else:\n",
    "                display = str(value)\n",
    "\n",
    "            max_len = max(max_len, len(display))\n",
    "\n",
    "        new_width = min(max_w, max(min_w, max_len + padding))\n",
    "        ws.column_dimensions[col_letter].width = new_width\n",
    "\n",
    "    wb.save(FILE)\n",
    "\n",
    "\n",
    "def append_new_jobs_preserve_format(FILE, jobs_df, id_col=\"job_id\", sheet_name=None, default_estado=\"A aplicar\"):\n",
    "    \"\"\"\n",
    "    Appends only NEW rows (by id_col) to an existing formatted Excel, preserving all formatting.\n",
    "    Assumes headers are on row 1.\n",
    "    \"\"\"\n",
    "    wb = load_workbook(FILE)\n",
    "    ws = wb[sheet_name] if sheet_name else wb.active\n",
    "\n",
    "    # Read headers from Excel\n",
    "    headers = [ws.cell(row=1, column=c).value for c in range(1, ws.max_column + 1)]\n",
    "    header_to_col = {h: i+1 for i, h in enumerate(headers) if h is not None}\n",
    "\n",
    "    if id_col not in header_to_col:\n",
    "        raise ValueError(f\"'{id_col}' no está en el Excel. Headers actuales: {headers}\")\n",
    "\n",
    "    # Collect existing IDs from Excel (fast enough for normal sizes)\n",
    "    id_excel_col = header_to_col[id_col]\n",
    "    existing_ids = set()\n",
    "    for r in range(2, ws.max_row + 1):\n",
    "        v = ws.cell(row=r, column=id_excel_col).value\n",
    "        if v is not None and str(v).strip() != \"\":\n",
    "            existing_ids.add(str(v))\n",
    "\n",
    "    # Ensure jobs_df id is str\n",
    "    df = jobs_df.copy()\n",
    "    df[id_col] = df[id_col].astype(str)\n",
    "\n",
    "    # Filter only new rows\n",
    "    new_df = df[~df[id_col].isin(existing_ids)]\n",
    "    if new_df.empty:\n",
    "        return 0  # nothing appended\n",
    "\n",
    "    # If Estado column exists in Excel, ensure we can write default for new rows\n",
    "    estado_col = header_to_col.get(\"Estado\", None)\n",
    "\n",
    "    # Append rows at bottom\n",
    "    start_row = ws.max_row + 1\n",
    "\n",
    "    # We'll write only columns that exist in Excel (to preserve structure)\n",
    "    excel_cols_in_order = [h for h in headers if h is not None]\n",
    "\n",
    "    for i, row in enumerate(new_df.to_dict(orient=\"records\")):\n",
    "        excel_row = start_row + i\n",
    "\n",
    "        for h in excel_cols_in_order:\n",
    "            col = header_to_col[h]\n",
    "\n",
    "            if h == \"Estado\":\n",
    "                # default for newly added jobs\n",
    "                ws.cell(row=excel_row, column=col, value=default_estado)\n",
    "            else:\n",
    "                ws.cell(row=excel_row, column=col, value=row.get(h, None))\n",
    "\n",
    "        # If Excel has Estado but header list didn't include it for some reason\n",
    "        if estado_col and \"Estado\" not in header_to_col:\n",
    "            ws.cell(row=excel_row, column=estado_col, value=default_estado)\n",
    "\n",
    "    wb.save(FILE)\n",
    "    return len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bd68ae29-94a9-4049-80cb-f0713cfacf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 10 new rows\n"
     ]
    }
   ],
   "source": [
    "FILE = \"jobhunt.xlsx\"\n",
    "\n",
    "if not os.path.exists(FILE):\n",
    "    # first time: create + full formatting\n",
    "    jobs_df.to_excel(FILE, index=False)\n",
    "    format_jobhunt_excel(FILE)\n",
    "    auto_resize_columns(FILE)\n",
    "\n",
    "else:\n",
    "    # DO NOT to_excel() again — it wipes formatting\n",
    "    added = append_new_jobs_preserve_format(FILE, jobs_df, id_col=\"job_id\")\n",
    "    auto_resize_columns(FILE)\n",
    "    print(f\"Added {added} new rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35532b03-bb73-4b7c-8cd1-358f01e24c55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
